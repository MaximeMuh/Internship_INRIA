## Introduction

Ce d√©p√¥t rassemble le code et les notebooks r√©alis√©s durant mon **stage de recherche √† l‚ÄôINRIA Paris (√©quipe ARGO)**, effectu√© du **17/06/2024 au 04/09/2024** sous la supervision de **Marc Lelarge**. L‚Äôobjectif g√©n√©ral du stage √©tait d‚Äôexplorer, de mani√®re progressive et exp√©rimentale, les **liens entre l‚Äôassimilation de donn√©es** (pour des syst√®mes dynamiques physiques) et les **mod√®les g√©n√©ratifs de diffusion** (diffusion probabiliste, score-based, interpolants stochastiques), puis d‚Äôen **√©valuer la pertinence sur des donn√©es structur√©es** (images d‚Äôarbres couvrants uniformes ‚Äî UST ‚Äî et **graphes**).

Le travail est organis√© en √©tapes compl√©mentaires :
1) **Assimilation de donn√©es** : impl√©mentations de m√©thodes classiques (BLUE, 3D-VAR) et d√©monstrations sur des syst√®mes jouets (ex. pendule simple, attracteur de Lorenz) pour poser le cadre et les m√©triques.
2) **Mod√®les de diffusion (DDPM)** : mise en pratique sur des images (MNIST, CIFAR-10) afin d‚Äôacqu√©rir un socle op√©rationnel pour le d√©bruitage/g√©n√©ration et le conditionnement.
3) **Interpolants stochastiques (SDE/ODE)** : exp√©rimentation du cadre unifiant (flows/diffusions) d‚Äô**Albergo & Vanden-Eijnden** ‚Äî d‚Äôabord en **2D** (passage contr√¥l√© entre deux distributions), puis sur **donn√©es visuelles** (ex. *Oxford Flowers*).
4) **Application √† l‚Äô‚Äúassimilation‚Äù d‚ÄôUST par l‚Äôimage** : **inpainting conditionnel** d‚Äôarbres couvrants uniformes (UST) avec **resampling** pour am√©liorer la coh√©rence locale des r√©gions compl√©t√©es.
5) **Diffusion sur graphes (UST)** : tentative de g√©n√©ration **discr√®te** sur matrices d‚Äôadjacence (inspir√©e des approches ‚Äúdiscrete diffusion‚Äù), avec **contraintes topologiques** (connectivit√©, acyclicit√©, nombre d‚Äôar√™tes) via la fonction de perte et un **post-processing** vers des UST.

### Ce que contient le d√©p√¥t (grandes lignes)

- **Assimilation (BLUE, 3D-VAR)** : notebooks p√©dagogiques et reproductibles avec visualisations des trajectoires assimil√©es.
- **Diffusion (DDPM)** : notebook d‚Äôentra√Ænement/√©chantillonnage sur images (d√©mos MNIST / CIFAR-10).
- **Interpolants stochastiques** : deux notebooks (cas **2D** et **images**) illustrant SDE/ODE et la r√©solution associ√©e.
- **Inpainting UST (par l‚Äôimage)** : script de g√©n√©ration de masques et **compl√©tion par diffusion** (inpainting conditionnel avec resampling).
- **Diffusion sur graphes (UST)** : notebook de diffusion **discr√®te** sur **matrices d‚Äôadjacence** (g√©n√©ration ‚Üí contraintes ‚Üí post-traitement en UST).
- **Donn√©es utilitaires** : g√©n√©ration d‚ÄôUST (algorithme de Wilson), jeux d‚Äôessai et sorties visuelles (selon disponibilit√© locale).

> Le **rapport de stage (PDF)** associ√© ‚Äî qui pr√©sente le contexte, les choix m√©thodologiques, les r√©sultats et la discussion ‚Äî est inclus dans le d√©p√¥t et sert de r√©f√©rence scientifique √† ce code.


## 1. Assimilation de donn√©es ‚Äî `BLUE_3DVAR.ipynb`

Ce notebook introduit les **principes fondamentaux de l‚Äôassimilation de donn√©es**, tels qu‚Äôutilis√©s dans les sciences physiques (m√©t√©orologie, oc√©anographie, dynamique des syst√®mes).  
L‚Äôobjectif est de comprendre comment combiner des **pr√©visions issues d‚Äôun mod√®le** et des **observations bruit√©es** afin d‚Äôobtenir un **√©tat estim√© optimal**.

### Contenu
- Pr√©sentation des m√©thodes **BLUE (Best Linear Unbiased Estimator)** et **3D-VAR**.  
- Impl√©mentations sur deux syst√®mes physiques de r√©f√©rence :  
  - un **pendule simple**,  
  - le **syst√®me de Lorenz** (attracteur chaotique).  
- Visualisation des trajectoires assimil√©es par rapport aux trajectoires vraies et aux observations bruit√©es.  
- Illustration du **r√¥le des matrices de covariance** (erreurs de fond *B* et d‚Äôobservation *R*) et du **gain optimal K**.

### Objectifs p√©dagogiques
- Comprendre les fondements statistiques de l‚Äôassimilation de donn√©es.  
- Manipuler les √©quations de mise √† jour de l‚Äô√©tat et du gain de Kalman.  
- Acqu√©rir un cadre g√©n√©ral pour l‚Äôint√©gration de connaissances physiques dans des mod√®les d‚Äôapprentissage.

### R√©sultats
- Les impl√©mentations montrent que les algorithmes **BLUE** et **3D-VAR** permettent de corriger efficacement les √©carts entre le mod√®le et les observations, en ramenant les trajectoires estim√©es vers la dynamique r√©elle.  
- Ces exercices constituent la base du travail ult√©rieur sur les **mod√®les de diffusion appliqu√©s √† l‚Äôassimilation**.

---

## 2. Mod√®les de diffusion ‚Äî `ddpm_nano_completed.ipynb`

Ce notebook constitue une **introduction pratique aux mod√®les de diffusion g√©n√©ratifs**, √† partir de l‚Äôarticle fondateur de **Ho, Jain & Abbeel (2020)** :  
> *Denoising Diffusion Probabilistic Models (DDPM)*, arXiv:2006.11239.

### Contenu
- Impl√©mentation simplifi√©e d‚Äôun mod√®le DDPM (‚Äúnano version‚Äù) en **PyTorch**.  
- Application sur les bases d‚Äôimages **MNIST** et **CIFAR-10**.  
- √âtapes d‚Äôentra√Ænement et d‚Äô√©chantillonnage illustr√©es :  
  - *forward diffusion* (ajout progressif de bruit gaussien),  
  - *reverse denoising* (r√©tro-processus appris).  
- Visualisation de la diffusion et du d√©bruitage √† diff√©rents pas de temps.  
- Comparaison qualitative avec d‚Äôautres mod√®les g√©n√©ratifs (ex. GAN, VAE).

### Objectifs
- Assimiler le fonctionnement des processus de diffusion et leur stabilit√© d‚Äôapprentissage.  
- Comprendre le r√¥le du bruit, de la variance et de la pr√©diction de bruit (*Œµ-prediction*).  
- Pr√©parer les travaux ult√©rieurs sur les **mod√®les d‚Äôinterpolants stochastiques (SDE / ODE)** et leur application √† l‚Äôassimilation de donn√©es.

### R√©sultats
- Le mod√®le g√©n√®re des √©chantillons r√©alistes √† partir de bruit pur.  
- L‚Äô√©volution visuelle des √©tapes de d√©bruitage confirme la bonne convergence du mod√®le et la compr√©hension du processus de diffusion.  
- Ce notebook sert de **brique exp√©rimentale de r√©f√©rence** pour les sections suivantes (inpainting, diffusion sur graphes, interpolants).

---

## 3. Interpolants stochastiques (SDE / ODE)

Cette partie du projet s‚Äôappuie sur les travaux r√©cents de **M. S. Albergo et E. Vanden-Eijnden** (*Stochastic Interpolants: A Unifying Framework for Flows and Diffusions*, 2023).  
L‚Äôobjectif est d‚Äôintroduire un **cadre continu et unificateur** pour les mod√®les g√©n√©ratifs, en montrant comment les √©quations diff√©rentielles stochastiques (SDE) et d√©terministes (ODE) peuvent relier deux distributions de probabilit√© arbitraires au moyen d‚Äôun **interpolant stochastique**.

Deux notebooks compl√©mentaires sont propos√©s :

---

### üîπ `interpolant_ODE_SDE_2D_notebook.ipynb`

Ce notebook a √©t√© con√ßu comme un **support de cours illustr√©** pour pr√©senter les fondements th√©oriques et num√©riques des interpolants stochastiques.

#### Contenu
- Introduction conceptuelle aux interpolants stochastiques et √† leur lien avec les mod√®les de diffusion.  
- D√©finition formelle de l‚Äôinterpolant :
  \[
  x_t = I(t, x_0, x_1, z)
  \]
  reliant deux distributions \( \rho_0 \) et \( \rho_1 \) via un bruit latent \( z \).  
- Pr√©sentation des √©quations de **Fokker‚ÄìPlanck**, du **champ de vitesse \( b_t \)**, du **score \( s_t \)** et du **d√©noiseur \( \eta_t \)**.  
- Impl√©mentation en PyTorch d‚Äôun interpolant 2D entre deux distributions arbitraires :  
  - Distribution initiale \( \rho_0 \) : gaussienne centr√©e ;  
  - Distribution cible \( \rho_1 \) : forme sinuso√Ødale / en ‚Äúvague‚Äù.  
- Estimation des champs \( b \), \( s \) et \( \eta \) via un petit r√©seau de neurones enti√®rement connect√©.  
- Simulation et visualisation de trajectoires g√©n√©r√©es par ODE et SDE.

#### Objectifs
- Relier les mod√®les g√©n√©ratifs √† un cadre probabiliste continu.  
- Comprendre la diff√©rence entre une √©volution **stochastique (SDE)** et **d√©terministe (ODE)**.  
- Visualiser comment les trajectoires stochastiques connectent les deux distributions.

#### R√©sultats
- Les interpolants permettent de g√©n√©rer des points conformes √† la distribution cible \( \rho_1 \) √† partir de la gaussienne initiale \( \rho_0 \).  
- Les trajectoires obtenues par SDE sont plus diverses, tandis que celles issues de l‚ÄôODE sont plus r√©guli√®res.  
- Ce notebook illustre de mani√®re p√©dagogique la continuit√© entre les mod√®les de diffusion et les normalizing flows.

---

### üîπ `interpolant_ODE_SDE_flowers_64_notebook.ipynb`

Apr√®s validation sur des distributions 2D simples, le cadre est √©tendu √† un **cas visuel r√©el** : le **dataset *Oxford Flowers 64√ó64***.  
Le but est d‚Äôobserver si les interpolants stochastiques peuvent reproduire des structures visuelles complexes.

#### Contenu
- Chargement du dataset *Oxford Flowers* et pr√©-traitement des images.  
- Impl√©mentation du m√™me mod√®le d‚Äôinterpolant (SDE/ODE), adapt√© √† des entr√©es haute dimension.  
- Entra√Ænement sur le **cluster de calcul CLEPS (INRIA)** pendant ~50 √©poques.  
- √âchantillonnage de nouvelles images via int√©gration des √©quations diff√©rentielles associ√©es.  
- Visualisation finale des images g√©n√©r√©es √† l‚Äô√©poque 35 :

![R√©sultats sur le dataset Oxford Flowers (epoch 35)](interpolant_ODE_SDE/results/results_epoch_35_flowers.png)
![R√©sultats sur le dataset Oxford Flowers (epoch 60)](interpolant_ODE_SDE/results/results_epoch_60_flowers.png)
#### R√©sultats
- Les images g√©n√©r√©es sont **visuellement coh√©rentes** : formes florales, d√©grad√©s de couleurs, textures naturelles.  
- Les interpolants reproduisent fid√®lement la diversit√© des donn√©es, confirmant leur **capacit√© de mod√©lisation continue** entre bruit et structure.  
- La m√©thode SDE conserve une plus grande variabilit√©, tandis que l‚ÄôODE tend vers une reconstruction plus stable mais moins expressive.

#### Apports du travail
- Premi√®re mise en ≈ìuvre pratique du formalisme ‚ÄúStochastic Interpolants‚Äù au sein de l‚Äô√©quipe ARGO.  
- R√©daction d‚Äôun **notebook p√©dagogique destin√© aux √©l√®ves de l‚Äô√âcole Polytechnique**, visant √† introduire les interpolants dans le cadre des mod√®les de diffusion.  
- Base de comparaison pour les exp√©riences ult√©rieures d‚Äô**assimilation de donn√©es** sur images et sur graphes.

---

> Ces deux notebooks forment le c≈ìur th√©orique du stage : ils montrent comment un processus continu d‚Äôinterpolation probabiliste peut √™tre exploit√© pour la g√©n√©ration de donn√©es, et ouvrent la voie √† leur utilisation dans des contextes d‚Äôassimilation.



## 4. Inpainting sur des arbres couvrants uniformes (UST)

Cette partie du projet s‚Äôint√©resse √† l‚Äôapplication des mod√®les de diffusion √† des **donn√©es structur√©es de type graphe**, sous forme d‚Äôimages de **labyrinthes repr√©sentant des arbres couvrants uniformes (Uniform Spanning Trees, UST)**.  
L‚Äôobjectif est d‚Äôexaminer si un **mod√®le de diffusion conditionnelle** peut **‚Äúassimiler‚Äù des propri√©t√©s physiques ou structurelles** telles que :
- **la connexit√©** (tous les n≈ìuds sont reli√©s),  
- **l‚Äôabsence de cycles**,  
- **le nombre d‚Äôar√™tes fixe** pour un graphe donn√©.

Le travail est regroup√© dans le dossier `mazes_inpainting_and_utils/`, qui contient les scripts suivants :

| Fichier | Description |
|----------|--------------|
| `inpainting_generating_chosen_mask.py` | Script principal d‚Äôinpainting : permet de g√©n√©rer des masques arbitraires sur les UST et de compl√©ter les zones manquantes via un mod√®le de diffusion. L‚Äôutilisateur peut **dessiner manuellement** le masque √† reconstituer. |
| `inpainting_mazes_training_generation_fixed_mask.py` | Variante exp√©rimentale permettant d‚Äôentra√Æner le mod√®le avec un masque fixe et de comparer les performances selon diff√©rents taux de masquage. |
| `utils_*.py` *(selon version)* | Fonctions auxiliaires pour la g√©n√©ration d‚ÄôUST (algorithme de Wilson), le traitement d‚Äôimages et la visualisation. |

---

### Principe

L‚Äôid√©e est de consid√©rer les images d‚ÄôUST comme des ‚Äúcartes‚Äù partielles d‚Äôun syst√®me √† compl√©ter.  
Une portion du graphe est masqu√©e, puis le mod√®le tente de **reconstruire la partie manquante** en respectant la coh√©rence globale.  

L‚Äôapproche repose sur :
1. un **mod√®le de diffusion conditionn√©** sur les r√©gions visibles de l‚Äôimage ;  
2. une **technique de resampling** inspir√©e de *RePaint* (Lugmayr et al., 2022),  
   qui permet de r√©alimenter en variance les zones reconstruites afin d‚Äôam√©liorer la continuit√© entre parties connues et compl√©t√©es.

---

### Fonctionnement du script

- Le script charge un ensemble d‚ÄôUST g√©n√©r√©s par l‚Äôalgorithme de **Wilson**.  
- L‚Äôutilisateur d√©finit un **masque** (manuellement ou al√©atoirement) repr√©sentant les zones √† reconstruire.  
- Le mod√®le de diffusion r√©alise un processus de **bruitage / d√©bruitage** sur l‚Äôimage compl√®te, mais ne modifie que les zones masqu√©es.  
- Le r√©sultat est sauvegard√© et affich√© pour comparaison avec l‚Äôimage initiale.

---

### Exemples de r√©sultats

#### Exemple 1 ‚Äì Masque manuel
L‚Äôutilisateur s√©lectionne un masque de forme libre.  
Le mod√®le tente ensuite de combler les zones manquantes.

![Inpainting avec masque manuel](mazes_inpainting_and_utils/results/result_mask_random.png)

#### Exemple 2 ‚Äì Masque complet
Lorsque le masque couvre toute l‚Äôimage, le mod√®le r√©alise une **g√©n√©ration compl√®te** √† partir du bruit initial.

![Inpainting sur masque complet](mazes_inpainting_and_utils/results/result_inpainting_full_mask.png)


---

### Interpr√©tation des r√©sultats

Les reconstructions produites montrent une **bonne coh√©rence visuelle** avec les images originales :  
les motifs et textures locales sont correctement reproduits, les ar√™tes s‚Äôalignent globalement avec la structure attendue.  

Cependant :
- certaines **zones contiennent des cycles** (non d√©sir√©s) ;  
- la **connexit√© n‚Äôest pas toujours assur√©e**, avec parfois des ar√™tes isol√©es ;  
- les propri√©t√©s topologiques des UST ne sont donc **pas compl√®tement apprises** par le mod√®le de diffusion.

Ces limites montrent que si le mod√®le capture bien les **corr√©lations locales**, il n‚Äôint√®gre pas encore la **structure globale** impos√©e par la th√©orie des graphes.  
Une piste d‚Äôam√©lioration, √©voqu√©e dans le rapport, serait d‚Äôint√©grer :
- des **contraintes structurelles explicites** (p√©nalisation de cycles, connexit√©) dans la loss,  
- ou une **diffusion directement sur le graphe** plut√¥t que sur l‚Äôimage.

---

### Objectif de cette exp√©rimentation

Ce travail d‚Äôinpainting sert de **pont conceptuel** entre la diffusion sur images et l‚Äôassimilation de donn√©es physiques :  
comme dans un syst√®me r√©el o√π certaines observations sont manquantes, le mod√®le doit ‚Äúassimiler‚Äù des informations partielles pour **reconstruire un √©tat complet coh√©rent**.

Il constitue donc une **premi√®re tentative d‚Äôassimilation par mod√®le de diffusion**, avant les exp√©riences suivantes sur graphes.

---

> Ces exp√©riences montrent que les mod√®les de diffusion peuvent restituer efficacement la structure apparente d‚Äôun syst√®me, mais que la pr√©servation des lois internes (ici les propri√©t√©s d‚Äôun UST) n√©cessite des contraintes explicites.  
> Ce constat motivera la derni√®re partie du projet : **la diffusion directement sur graphes**, afin de capturer les relations topologiques sans passer par l‚Äôimage.


## 5. Diffusion sur graphes ‚Äî G√©n√©ration d‚ÄôUST

√Ä la suite des limites observ√©es avec la m√©thode d‚Äô**inpainting par diffusion sur images**, une nouvelle approche a √©t√© test√©e :  
appliquer la **diffusion directement sur les graphes** eux-m√™mes, plut√¥t que sur leurs repr√©sentations visuelles.  

L‚Äôobjectif est de voir si un **mod√®le de diffusion discr√®te** peut apprendre √† g√©n√©rer des **arbres couvrants uniformes (UST)** ‚Äî c‚Äôest-√†-dire des graphes connexes, acycliques et couvrant tous les n≈ìuds ‚Äî √† partir d‚Äôune matrice d‚Äôadjacence bruit√©e.

---

### Structure du dossier `UST_diffusion/`

| Fichier / notebook | R√¥le |
|---------------------|------|
| `sample_ppgn.ipynb` | Notebook principal : visualisation et √©chantillonnage des graphes g√©n√©r√©s par diffusion. |
| `train_ppgn_simple_adj_neigh.py` | Script d‚Äôentra√Ænement du mod√®le de diffusion sur matrices d‚Äôadjacence. Impl√©mente la logique de bruitage / d√©bruitage et la loss. |
| `model_ppgn.py` | D√©finition du r√©seau de neurones principal (**PPGN** ‚Äî Powerful Graph Network), architecture inspir√©e des *Graph Neural Networks* (message passing). |
| `graphs.py` | Fonctions utilitaires : g√©n√©ration de graphes de r√©f√©rence via l‚Äôalgorithme de **Wilson**, cr√©ation de matrices d‚Äôadjacence, visualisation et mesure de propri√©t√©s (connexit√©, cycles, etc.). |
| `data/` *(optionnel)* | Contient les datasets de graphes utilis√©s pour l‚Äôentra√Ænement et la validation. |

---

### M√©thodologie

#### 1. Repr√©sentation des donn√©es
Chaque graphe est repr√©sent√© par sa **matrice d‚Äôadjacence** \( A \in \{0,1\}^{n \times n} \).  
Les graphes d‚Äôentra√Ænement sont des **UST g√©n√©r√©s par l‚Äôalgorithme de Wilson**.  

#### 2. Processus de diffusion
Un **bruit discret** est ajout√© sur les ar√™tes :
- √† chaque √©tape, certaines ar√™tes sont ajout√©es ou supprim√©es avec une probabilit√© donn√©e ;
- le mod√®le apprend √† pr√©dire le bruit ajout√© entre \( A_t \) (bruit√©) et \( A_{t-1} \) (√©tat pr√©c√©dent).

#### 3. R√©seau utilis√©
Le mod√®le est bas√© sur une architecture **PPGN (Powerful Graph Network)**, adapt√©e √† la manipulation de matrices d‚Äôadjacence :  
- elle encode les relations entre n≈ìuds via un m√©canisme de message passing ;  
- elle pr√©serve la permutation-invariance ;  
- elle permet d‚Äôapprendre des repr√©sentations locales et globales du graphe.

#### 4. Fonction de perte
La loss int√®gre plusieurs termes :
- **erreur de reconstruction** (pr√©diction du bruit) ;
- **p√©nalit√©s structurelles** :
  - nombre de cycles,
  - connexit√© du graphe,
  - nombre total d‚Äôar√™tes (fix√© √† \( n-1 \) pour un UST),
  - n≈ìuds isol√©s.  

Chaque p√©nalisation est pond√©r√©e par un hyperparam√®tre, ajust√© exp√©rimentalement.

---

### Exp√©riences

Les graphes ont √©t√© g√©n√©r√©s et entra√Æn√©s pour diff√©rentes tailles de grilles (de \(4\times4\) √† \(10\times10\)).  
Les figures ci-dessous illustrent le **d√©bruitage progressif** d‚Äôun graphe vers une structure proche d‚Äôun UST.

| √âtape | Description | Observation |
|-------|--------------|-------------|
| 1 | Graphe bruit√© (ar√™tes al√©atoires) | Nombreux cycles et composantes isol√©es |
| 2 | Diffusion discr√®te sur 64 √©tapes | Suppression progressive des cycles |
| 3 | Graphe reconstruit | Structure proche d‚Äôun arbre couvrant |

√Ä la fin du processus, les graphes produits pr√©sentent souvent **moins de cycles** et une **meilleure connexit√©** que les graphes al√©atoires de d√©part.

---

### √âvaluation quantitative

Pour quantifier la qualit√© des graphes g√©n√©r√©s :
- On applique un **post-traitement** supprimant les cycles restants et connectant les composantes isol√©es.
- On compte le **nombre moyen de modifications n√©cessaires** pour transformer le graphe g√©n√©r√© en un v√©ritable UST.

| Taille du graphe | Changements moyens (graphes al√©atoires) | Changements moyens (graphes g√©n√©r√©s par diffusion) |
|------------------:|----------------------------------------:|----------------------------------------------------:|
| 16 n≈ìuds | 7.3 | **2.5** |
| 36 n≈ìuds | 13.8 | **7.1** |
| 64 n≈ìuds | 21.4 | **11.3** |

Les graphes issus du mod√®le n√©cessitent environ **deux fois moins de corrections** que des graphes purement al√©atoires, ce qui montre que la diffusion apprend partiellement les propri√©t√©s structurelles recherch√©es.

---

### Interpr√©tation et perspectives

- Le mod√®le de diffusion **assimile partiellement les lois structurelles** des arbres couvrants : les graphes g√©n√©r√©s sont souvent proches d‚ÄôUST, surtout pour de petites tailles.  
- Pour les graphes plus grands, les performances se d√©gradent √† cause :
  - de la **sparsit√©** croissante des matrices d‚Äôadjacence,  
  - d‚Äôun **manque de capacit√©** du mod√®le,  
  - et de la **difficult√© de r√©gularisation** des contraintes topologiques.

Des pistes d‚Äôam√©lioration propos√©es :
- repr√©senter les graphes sous forme de **vecteurs d‚Äôar√™tes autoris√©es** plut√¥t que matrices carr√©es ;
- introduire une **p√©nalisation adaptative** (cycles / connexit√©) au cours de la g√©n√©ration ;
- combiner diffusion discr√®te et apprentissage par renforcement pour contraindre la topologie en ligne.

---

### Bilan de cette derni√®re √©tape

Cette exp√©rimentation conclut le stage en montrant la **faisabilit√© d‚Äôune diffusion sur graphes** :  
m√™me si les mod√®les ne captent pas encore toutes les propri√©t√©s physiques, ils constituent une premi√®re base pour une **assimilation de donn√©es topologique**.  

> En somme, la transition de l‚Äôinpainting d‚Äôimages vers la diffusion sur graphes repr√©sente un changement d‚Äô√©chelle conceptuel :  
> passer d‚Äôune assimilation ‚Äúvisuelle‚Äù √† une assimilation ‚Äústructurelle‚Äù, plus proche des syst√®mes physiques mod√©lis√©s par graphes.


