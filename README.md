## Introduction

This repository contains the code and notebooks developed during my **research internship at INRIA Paris (ARGO team)** under the supervision of **Marc Lelarge**. The general objective of the internship was to explore, in a progressive and experimental manner, the **links between data assimilation** (for physical dynamical systems) and **generative diffusion models** (probabilistic diffusion, score-based, stochastic interpolants), and then to **evaluate their relevance on structured data** (images of Uniform Spanning Treesâ€”USTâ€”and **graphs**).

The work is organized into complementary stages:
1) **Data Assimilation**: Implementations of classical methods (BLUE, 3D-VAR) and demonstrations on toy systems (e.g., simple pendulum, Lorenz attractor) to establish the framework and metrics.
2) **Diffusion Models (DDPM)**: Practical application on images (MNIST, CIFAR-10) to acquire an operational foundation for denoising/generation and conditioning.
3) **Stochastic Interpolants (SDE/ODE)**: Experimentation with the unifying framework (flows/diffusions) of **Albergo & Vanden-Eijnden**â€”first in **2D** (controlled passage between two distributions), then on **visual data** (e.g., *Oxford Flowers*).
4) **Application to UST "Assimilation" via Images**: **Conditional inpainting** of Uniform Spanning Trees (UST) with **resampling** to improve the local coherence of the completed regions.
5) **Diffusion on Graphs (UST)**: Attempt at **discrete** generation on adjacency matrices (inspired by "discrete diffusion" approaches), with **topological constraints** (connectivity, acyclicity, number of edges) via the loss function and **post-processing** into USTs.

### What the repository contains (broad strokes)

- **Assimilation (BLUE, 3D-VAR)**: Educational and reproducible notebooks with visualizations of assimilated trajectories.
- **Diffusion (DDPM)**: Training/sampling notebook on images (MNIST / CIFAR-10 demos).
- **Stochastic Interpolants**: Two notebooks ( **2D** case and **images**) illustrating SDE/ODE and their associated solvers.
- **UST Inpainting (by image)**: Script for mask generation and **diffusion completion** (conditional inpainting with resampling).
- **Diffusion on Graphs (UST)**: Notebook for **discrete** diffusion on **adjacency matrices** (generation â†’ constraints â†’ post-processing into USTs).
- **Utility Data**: UST generation (Wilson's algorithm), test datasets, and visual outputs (subject to local availability).


## 1. Data Assimilation â€” `BLUE_3DVAR.ipynb`

This notebook introduces the **fundamental principles of data assimilation**, as used in the physical sciences (meteorology, oceanography, system dynamics).
The objective is to understand how to combine **forecasts from a model** and **noisy observations** to obtain an **optimal estimated state**.

### Content
- Presentation of **BLUE (Best Linear Unbiased Estimator)** and **3D-VAR** methods.
- Implementations on two reference physical systems:
  - a **simple pendulum**,
  - the **Lorenz system** (chaotic attractor).
- Visualization of assimilated trajectories compared to true trajectories and noisy observations.
- Illustration of the **role of covariance matrices** (background error *B* and observation error *R*) and the **optimal gain K**.

### Learning Objectives
- Understand the statistical foundations of data assimilation.
- Manipulate the update equations for the state and the Kalman gain.
- Acquire a general framework for integrating physical knowledge into learning models.

### Results
- The implementations show that the **BLUE** and **3D-VAR** algorithms effectively correct discrepancies between the model and the observations, bringing the estimated trajectories back towards the real dynamics.
- These exercises form the basis for subsequent work on **diffusion models applied to assimilation**.

---

## 2. Diffusion Models â€” `ddpm_nano_completed.ipynb`

This notebook provides a **practical introduction to generative diffusion models**, based on the founding paper by **Ho, Jain & Abbeel (2020)**:
> *Denoising Diffusion Probabilistic Models (DDPM)*, arXiv:2006.11239.

### Content
- Simplified implementation of a DDPM model ("nano version") in **PyTorch**.
- Application on the **MNIST** and **CIFAR-10** image datasets.
- Illustrated training and sampling steps:
  - *forward diffusion* (progressive addition of Gaussian noise),
  - *reverse denoising* (learned reverse process).
- Visualization of diffusion and denoising at different timesteps.
- Qualitative comparison with other generative models (e.g., GANs, VAEs).

### Objectives
- Assimilate the functioning of diffusion processes and their training stability.
- Understand the role of noise, variance, and **noise prediction (Îµ-prediction)**.
- Prepare for subsequent work on **stochastic interpolant models (SDE / ODE)** and their application to data assimilation.

### Results
- The model generates realistic samples from pure noise.
- The visual evolution of the denoising steps confirms the model's good convergence and understanding of the diffusion process.
- This notebook serves as a **foundational experimental building block** for the following sections (inpainting, diffusion on graphs, interpolants).

---

## 3. Stochastic Interpolants (SDE / ODE)

This part of the project is based on the recent work of **M. S. Albergo and E. Vanden-Eijnden** (*Stochastic Interpolants: A Unifying Framework for Flows and Diffusions*, 2023).
The objective is to introduce a **continuous and unifying framework** for generative models, by showing how stochastic (SDE) and deterministic (ODE) differential equations can link two arbitrary probability distributions by means of a **stochastic interpolant**.

Two complementary notebooks are provided:

---

### ğŸ”¹ `interpolant_ODE_SDE_2D_notebook.ipynb`

This notebook was designed as **illustrated course material** to present the theoretical and numerical foundations of stochastic interpolants.

#### Content
- Conceptual introduction to stochastic interpolants and their link with diffusion models.
- Formal definition of the interpolant:
  \[
  x_t = I(t, x_0, x_1, z)
  \]
  linking two distributions \( \rho_0 \) and \( \rho_1 \) via a latent noise \( z \).
- Presentation of the **Fokkerâ€“Planck** equations, the **velocity field \( b_t \)**, the **score \( s_t \)**, and the **denoiser \( \eta_t \)**.
- PyTorch implementation of a 2D interpolant between two arbitrary distributions:
  - Initial distribution \( \rho_0 \): centered Gaussian;
  - Target distribution \( \rho_1 \): sinusoidal / "wave" shape.
- Estimation of the fields \( b \), \( s \), and \( \eta \) via a small fully connected neural network.
- Simulation and visualization of trajectories generated by ODE and SDE.

#### Objectives
- Connect generative models to a continuous probabilistic framework.
- Understand the difference between **stochastic (SDE)** and **deterministic (ODE)** evolution.
- Visualize how stochastic trajectories connect the two distributions.

#### Results
- The interpolants succeed in generating points conforming to the target distribution \( \rho_1 \) from the initial Gaussian \( \rho_0 \).
- The trajectories obtained by SDE are more diverse, while those from the ODE are smoother.
- This notebook provides an educational illustration of the continuity between diffusion models and normalizing flows.

---

### ğŸ”¹ `interpolant_ODE_SDE_flowers_64_notebook.ipynb`

After validation on simple 2D distributions, the framework is extended to a **real-world visual case**: the ** *Oxford Flowers 64Ã—64* dataset**.
The goal is to observe whether stochastic interpolants can reproduce complex visual structures.

#### Content
- Loading the *Oxford Flowers* dataset and pre-processing the images.
- Implementation of the same interpolant model (SDE/ODE), adapted for high-dimensional inputs.
- Training on the **CLEPS computing cluster (INRIA)** for ~50 epochs.
- Sampling of new images via integration of the associated differential equations.
- Final visualization of images generated at epoch 35:

![Results on the Oxford Flowers dataset (epoch 35)](interpolant_ODE_SDE/results/results_epoch_35_flowers.png)
![Results on the Oxford Flowers dataset (epoch 60)](interpolant_ODE_SDE/results/results_epoch_60_flowers.png)

#### Results
- The generated images are **visually coherent**: floral shapes, color gradients, natural textures.
- The interpolants faithfully reproduce the diversity of the data, confirming their **continuous modeling capability** between noise and structure.
- The SDE method retains greater variability, whereas the ODE tends towards a more stable but less expressive reconstruction.

#### Contributions of this work
- First practical implementation of the "Stochastic Interpolants" formalism within the ARGO team.
- Writing of an **educational notebook intended for students at Ã‰cole Polytechnique**, aiming to introduce interpolants within the context of diffusion models.
- A baseline for comparison for subsequent **data assimilation** experiments on images and graphs.

---

> These two notebooks form the theoretical core of the internship: they show how a continuous probabilistic interpolation process can be exploited for data generation, and pave the way for their use in assimilation contexts.

## 4. Inpainting on Uniform Spanning Trees (UST)

This part of the project focuses on applying diffusion models to **structured graph-like data**, in the form of images of **mazes representing Uniform Spanning Trees (UST)**.
The objective is to examine whether a **conditional diffusion model** can **"assimilate" physical or structural properties** such as:
- **connectivity** (all nodes are connected),
- **acyclicity** (absence of cycles),
- **the fixed number of edges** for a given graph.

The work is grouped in the `mazes_inpainting_and_utils/` directory, which contains the following scripts:

| File | Description |
|----------|--------------|
| `inpainting_generating_chosen_mask.py` | Main inpainting script: allows generating arbitrary masks on USTs and completing the missing areas via a diffusion model. The user can **manually draw** the mask to be reconstructed. |
| `inpainting_mazes_training_generation_fixed_mask.py` | Experimental variant for training the model with a fixed mask and comparing performance across different masking rates. |
| `utils_*.py` *(by version)* | Helper functions for UST generation (Wilson's algorithm), image processing, and visualization. |

---

### Principle

The idea is to consider the UST images as partial "maps" of a system to be completed.
A portion of the graph is masked, and the model then attempts to **reconstruct the missing part** while respecting global coherence.

The approach relies on:
1. a **diffusion model conditioned** on the visible regions of the image;
2. a **resampling technique** inspired by *RePaint* (Lugmayr et al., 2022),
   which re-injects variance into the reconstructed areas to improve continuity between the known and completed parts.

---

### How the script works

- The script loads a set of USTs generated by **Wilson's algorithm**.
- The user defines a **mask** (manually or randomly) representing the areas to be reconstructed.
- The diffusion model performs a **noising/denoising** process on the complete image, but only modifies the masked areas.
- The result is saved and displayed for comparison with the original image.

---

### Example Results

#### Example 1 â€“ Manual Mask
The user selects a free-form mask.
The model then attempts to fill in the missing areas.

![Inpainting with manual mask](UST_inpainting/results/result_mask_random.png)

#### Example 2 â€“ Full Mask
When the mask covers the entire image, the model performs **complete generation** from the initial noise.

![Inpainting on full mask](UST_inpainting/results/result_inpainting_full_mask.png)

---

### Interpretation of Results

The reconstructions produced show **good visual coherence** with the original images:
local patterns and textures are correctly reproduced, and the edges generally align with the expected structure.

However:
- some **areas contain (undesired) cycles**;
- **connectivity is not always guaranteed**, with occasional isolated edges;
- the topological properties of USTs are therefore **not fully learned** by the diffusion model.

These limitations show that while the model captures **local correlations** well, it does not yet integrate the **global structure** imposed by graph theory.
An avenue for improvement, mentioned in the report, would be to integrate:
- **explicit structural constraints** (penalizing cycles, enforcing connectivity) into the loss,
- or **diffusion directly on the graph** rather than on the image.

---

### Objective of this Experiment

This inpainting work serves as a **conceptual bridge** between diffusion on images and the assimilation of physical data:
just as in a real system where some observations are missing, the model must "assimilate" partial information to **reconstruct a complete, coherent state**.

It thus constitutes a **first attempt at assimilation via a diffusion model**, preceding the subsequent experiments on graphs.

---

> These experiments show that diffusion models can effectively restore the apparent structure of a system, but that preserving internal laws (here, the properties of a UST) requires explicit constraints.
> This finding motivated the final part of the project: **diffusion directly on graphs**, in order to capture topological relationships without going through the image.

## 5. Diffusion on Graphs â€” UST Generation

Following the limitations observed with the **image-based diffusion inpainting** method, a new approach was tested:
applying **diffusion directly on the graphs** themselves, rather than on their visual representations.

The objective is to see if a **discrete diffusion model** can learn to generate **Uniform Spanning Trees (UST)**â€”that is, connected, acyclic graphs covering all nodesâ€”from a noisy adjacency matrix.

---

### Structure of the `UST_diffusion/` directory

| File / notebook | Role |
|---------------------|------|
| `sample_ppgn.ipynb` | Main notebook: visualization and sampling of graphs generated by diffusion. |
| `train_ppgn_simple_adj_neigh.py` | Training script for the diffusion model on adjacency matrices. Implements the noising/denoising logic and the loss. |
| `model_ppgn.py` | Definition of the main neural network (**PPGN**â€”Powerful Graph Network), an architecture inspired by *Graph Neural Networks* (message passing). |
| `graphs.py` | Utility functions: generation of reference graphs via **Wilson's algorithm**, creation of adjacency matrices, visualization, and measurement of properties (connectivity, cycles, etc.). |
| `data/` *(optional)* | Contains the graph datasets used for training and validation. |

---

### Methodology

#### 1. Data Representation
Each graph is represented by its **adjacency matrix** \( A \in \{0,1\}^{n \times n} \).
The training graphs are **USTs generated by Wilson's algorithm**.

#### 2. Diffusion Process
**Discrete noise** is added to the edges:
- at each step, some edges are added or removed with a given probability;
- the model learns to predict the noise added between \( A_t \) (noisy) and \( A_{t-1} \) (previous state).

#### 3. Network Used
The model is based on a **PPGN (Powerful Graph Network)** architecture, suitable for handling adjacency matrices:
- it encodes relationships between nodes via a message passing mechanism;
- it preserves permutation-invariance;
- it allows learning local and global representations of the graph.

#### 4. Loss Function
The loss integrates several terms:
- **reconstruction error** (noise prediction);
- **structural penalties**:
  - number of cycles,
  - graph connectivity,
  - total number of edges (fixed at \( n-1 \) for a UST),
  - isolated nodes.

Each penalty is weighted by a hyperparameter, adjusted experimentally.

---

### Experiments

Graphs were generated and trained for different grid sizes (from \(4\times4\) to \(10\times10\)).
The figures below illustrate the **progressive denoising** of a graph towards a structure resembling a UST.

| Step | Description | Observation |
|-------|--------------|-------------|
| 1 | Noisy graph (random edges) | Numerous cycles and isolated components |
| 2 | Discrete diffusion over 64 steps | Progressive removal of cycles |
| 3 | Reconstructed graph | Structure close to a spanning tree |

At the end of the process, the produced graphs often exhibit **fewer cycles** and **better connectivity** than the initial random graphs.

---

### Quantitative Evaluation

To quantify the quality of the generated graphs:
- **Post-processing** is applied to remove remaining cycles and connect isolated components.
- We count the **average number of modifications needed** to transform the generated graph into a true UST.

| Graph size | Avg. changes (random graphs) | Avg. changes (diffusion-generated graphs) |
|------------------:|-------------------------------:|----------------------------------------------------:|
| 16 nodes | 7.3 | **2.5** |
| 36 nodes | 13.8 | **7.1** |
| 64 nodes | 21.4 | **11.3** |

The graphs from the model require approximately **half as many corrections** as purely random graphs, which shows that the diffusion partially learns the desired structural properties.

---

### Interpretation and Outlook

- The diffusion model **partially assimilates the structural laws** of spanning trees: the generated graphs are often close to USTs, especially for small sizes.
- For larger graphs, performance degrades due to:
  - the **increasing sparsity** of the adjacency matrices,
  - a **lack of model capacity**,
  - and the **difficulty in regularizing** topological constraints.

Proposed avenues for improvement:
- represent graphs as **vectors of allowed edges** rather than square matrices;
- introduce an **adaptive penalization** (cycles / connectivity) during generation;
- combine discrete diffusion with reinforcement learning to constrain the topology online.

---

### Conclusion of this final stage

This experiment concludes the internship by showing the **feasibility of diffusion on graphs**:
even if the models do not yet capture all physical properties, they constitute a first basis for **topological data assimilation**.

> In summary, the transition from image inpainting to graph diffusion represents a conceptual shift in scale:
> moving from "visual" assimilation to "structural" assimilation, which is closer to physical systems modeled by graphs.



## Introduction

Ce dÃ©pÃ´t rassemble le code et les notebooks rÃ©alisÃ©s durant mon **stage de recherche Ã  lâ€™INRIA Paris (Ã©quipe ARGO)** sous la supervision de **Marc Lelarge**. Lâ€™objectif gÃ©nÃ©ral du stage Ã©tait dâ€™explorer, de maniÃ¨re progressive et expÃ©rimentale, les **liens entre lâ€™assimilation de donnÃ©es** (pour des systÃ¨mes dynamiques physiques) et les **modÃ¨les gÃ©nÃ©ratifs de diffusion** (diffusion probabiliste, score-based, interpolants stochastiques), puis dâ€™en **Ã©valuer la pertinence sur des donnÃ©es structurÃ©es** (images dâ€™arbres couvrants uniformes â€” UST â€” et **graphes**).

Le travail est organisÃ© en Ã©tapes complÃ©mentaires :
1) **Assimilation de donnÃ©es** : implÃ©mentations de mÃ©thodes classiques (BLUE, 3D-VAR) et dÃ©monstrations sur des systÃ¨mes jouets (ex. pendule simple, attracteur de Lorenz) pour poser le cadre et les mÃ©triques.
2) **ModÃ¨les de diffusion (DDPM)** : mise en pratique sur des images (MNIST, CIFAR-10) afin dâ€™acquÃ©rir un socle opÃ©rationnel pour le dÃ©bruitage/gÃ©nÃ©ration et le conditionnement.
3) **Interpolants stochastiques (SDE/ODE)** : expÃ©rimentation du cadre unifiant (flows/diffusions) dâ€™**Albergo & Vanden-Eijnden** â€” dâ€™abord en **2D** (passage contrÃ´lÃ© entre deux distributions), puis sur **donnÃ©es visuelles** (ex. *Oxford Flowers*).
4) **Application Ã  lâ€™â€œassimilationâ€ dâ€™UST par lâ€™image** : **inpainting conditionnel** dâ€™arbres couvrants uniformes (UST) avec **resampling** pour amÃ©liorer la cohÃ©rence locale des rÃ©gions complÃ©tÃ©es.
5) **Diffusion sur graphes (UST)** : tentative de gÃ©nÃ©ration **discrÃ¨te** sur matrices dâ€™adjacence (inspirÃ©e des approches â€œdiscrete diffusionâ€), avec **contraintes topologiques** (connectivitÃ©, acyclicitÃ©, nombre dâ€™arÃªtes) via la fonction de perte et un **post-processing** vers des UST.

### Ce que contient le dÃ©pÃ´t (grandes lignes)

- **Assimilation (BLUE, 3D-VAR)** : notebooks pÃ©dagogiques et reproductibles avec visualisations des trajectoires assimilÃ©es.
- **Diffusion (DDPM)** : notebook dâ€™entraÃ®nement/Ã©chantillonnage sur images (dÃ©mos MNIST / CIFAR-10).
- **Interpolants stochastiques** : deux notebooks (cas **2D** et **images**) illustrant SDE/ODE et la rÃ©solution associÃ©e.
- **Inpainting UST (par lâ€™image)** : script de gÃ©nÃ©ration de masques et **complÃ©tion par diffusion** (inpainting conditionnel avec resampling).
- **Diffusion sur graphes (UST)** : notebook de diffusion **discrÃ¨te** sur **matrices dâ€™adjacence** (gÃ©nÃ©ration â†’ contraintes â†’ post-traitement en UST).
- **DonnÃ©es utilitaires** : gÃ©nÃ©ration dâ€™UST (algorithme de Wilson), jeux dâ€™essai et sorties visuelles (selon disponibilitÃ© locale).



## 1. Assimilation de donnÃ©es â€” `BLUE_3DVAR.ipynb`

Ce notebook introduit les **principes fondamentaux de lâ€™assimilation de donnÃ©es**, tels quâ€™utilisÃ©s dans les sciences physiques (mÃ©tÃ©orologie, ocÃ©anographie, dynamique des systÃ¨mes).  
Lâ€™objectif est de comprendre comment combiner des **prÃ©visions issues dâ€™un modÃ¨le** et des **observations bruitÃ©es** afin dâ€™obtenir un **Ã©tat estimÃ© optimal**.

### Contenu
- PrÃ©sentation des mÃ©thodes **BLUE (Best Linear Unbiased Estimator)** et **3D-VAR**.  
- ImplÃ©mentations sur deux systÃ¨mes physiques de rÃ©fÃ©rence :  
  - un **pendule simple**,  
  - le **systÃ¨me de Lorenz** (attracteur chaotique).  
- Visualisation des trajectoires assimilÃ©es par rapport aux trajectoires vraies et aux observations bruitÃ©es.  
- Illustration du **rÃ´le des matrices de covariance** (erreurs de fond *B* et dâ€™observation *R*) et du **gain optimal K**.

### Objectifs pÃ©dagogiques
- Comprendre les fondements statistiques de lâ€™assimilation de donnÃ©es.  
- Manipuler les Ã©quations de mise Ã  jour de lâ€™Ã©tat et du gain de Kalman.  
- AcquÃ©rir un cadre gÃ©nÃ©ral pour lâ€™intÃ©gration de connaissances physiques dans des modÃ¨les dâ€™apprentissage.

### RÃ©sultats
- Les implÃ©mentations montrent que les algorithmes **BLUE** et **3D-VAR** permettent de corriger efficacement les Ã©carts entre le modÃ¨le et les observations, en ramenant les trajectoires estimÃ©es vers la dynamique rÃ©elle.  
- Ces exercices constituent la base du travail ultÃ©rieur sur les **modÃ¨les de diffusion appliquÃ©s Ã  lâ€™assimilation**.

---

## 2. ModÃ¨les de diffusion â€” `ddpm_nano_completed.ipynb`

Ce notebook constitue une **introduction pratique aux modÃ¨les de diffusion gÃ©nÃ©ratifs**, Ã  partir de lâ€™article fondateur de **Ho, Jain & Abbeel (2020)** :  
> *Denoising Diffusion Probabilistic Models (DDPM)*, arXiv:2006.11239.

### Contenu
- ImplÃ©mentation simplifiÃ©e dâ€™un modÃ¨le DDPM (â€œnano versionâ€) en **PyTorch**.  
- Application sur les bases dâ€™images **MNIST** et **CIFAR-10**.  
- Ã‰tapes dâ€™entraÃ®nement et dâ€™Ã©chantillonnage illustrÃ©es :  
  - *forward diffusion* (ajout progressif de bruit gaussien),  
  - *reverse denoising* (rÃ©tro-processus appris).  
- Visualisation de la diffusion et du dÃ©bruitage Ã  diffÃ©rents pas de temps.  
- Comparaison qualitative avec dâ€™autres modÃ¨les gÃ©nÃ©ratifs (ex. GAN, VAE).

### Objectifs
- Assimiler le fonctionnement des processus de diffusion et leur stabilitÃ© dâ€™apprentissage.  
- Comprendre le rÃ´le du bruit, de la variance et de la prÃ©diction de bruit (*Îµ-prediction*).  
- PrÃ©parer les travaux ultÃ©rieurs sur les **modÃ¨les dâ€™interpolants stochastiques (SDE / ODE)** et leur application Ã  lâ€™assimilation de donnÃ©es.

### RÃ©sultats
- Le modÃ¨le gÃ©nÃ¨re des Ã©chantillons rÃ©alistes Ã  partir de bruit pur.  
- Lâ€™Ã©volution visuelle des Ã©tapes de dÃ©bruitage confirme la bonne convergence du modÃ¨le et la comprÃ©hension du processus de diffusion.  
- Ce notebook sert de **brique expÃ©rimentale de rÃ©fÃ©rence** pour les sections suivantes (inpainting, diffusion sur graphes, interpolants).

---

## 3. Interpolants stochastiques (SDE / ODE)

Cette partie du projet sâ€™appuie sur les travaux rÃ©cents de **M. S. Albergo et E. Vanden-Eijnden** (*Stochastic Interpolants: A Unifying Framework for Flows and Diffusions*, 2023).  
Lâ€™objectif est dâ€™introduire un **cadre continu et unificateur** pour les modÃ¨les gÃ©nÃ©ratifs, en montrant comment les Ã©quations diffÃ©rentielles stochastiques (SDE) et dÃ©terministes (ODE) peuvent relier deux distributions de probabilitÃ© arbitraires au moyen dâ€™un **interpolant stochastique**.

Deux notebooks complÃ©mentaires sont proposÃ©s :

---

### ğŸ”¹ `interpolant_ODE_SDE_2D_notebook.ipynb`

Ce notebook a Ã©tÃ© conÃ§u comme un **support de cours illustrÃ©** pour prÃ©senter les fondements thÃ©oriques et numÃ©riques des interpolants stochastiques.

#### Contenu
- Introduction conceptuelle aux interpolants stochastiques et Ã  leur lien avec les modÃ¨les de diffusion.  
- DÃ©finition formelle de lâ€™interpolant :
  \[
  x_t = I(t, x_0, x_1, z)
  \]
  reliant deux distributions \( \rho_0 \) et \( \rho_1 \) via un bruit latent \( z \).  
- PrÃ©sentation des Ã©quations de **Fokkerâ€“Planck**, du **champ de vitesse \( b_t \)**, du **score \( s_t \)** et du **dÃ©noiseur \( \eta_t \)**.  
- ImplÃ©mentation en PyTorch dâ€™un interpolant 2D entre deux distributions arbitraires :  
  - Distribution initiale \( \rho_0 \) : gaussienne centrÃ©e ;  
  - Distribution cible \( \rho_1 \) : forme sinusoÃ¯dale / en â€œvagueâ€.  
- Estimation des champs \( b \), \( s \) et \( \eta \) via un petit rÃ©seau de neurones entiÃ¨rement connectÃ©.  
- Simulation et visualisation de trajectoires gÃ©nÃ©rÃ©es par ODE et SDE.

#### Objectifs
- Relier les modÃ¨les gÃ©nÃ©ratifs Ã  un cadre probabiliste continu.  
- Comprendre la diffÃ©rence entre une Ã©volution **stochastique (SDE)** et **dÃ©terministe (ODE)**.  
- Visualiser comment les trajectoires stochastiques connectent les deux distributions.

#### RÃ©sultats
- Les interpolants permettent de gÃ©nÃ©rer des points conformes Ã  la distribution cible \( \rho_1 \) Ã  partir de la gaussienne initiale \( \rho_0 \).  
- Les trajectoires obtenues par SDE sont plus diverses, tandis que celles issues de lâ€™ODE sont plus rÃ©guliÃ¨res.  
- Ce notebook illustre de maniÃ¨re pÃ©dagogique la continuitÃ© entre les modÃ¨les de diffusion et les normalizing flows.

---

### ğŸ”¹ `interpolant_ODE_SDE_flowers_64_notebook.ipynb`

AprÃ¨s validation sur des distributions 2D simples, le cadre est Ã©tendu Ã  un **cas visuel rÃ©el** : le **dataset *Oxford Flowers 64Ã—64***.  
Le but est dâ€™observer si les interpolants stochastiques peuvent reproduire des structures visuelles complexes.

#### Contenu
- Chargement du dataset *Oxford Flowers* et prÃ©-traitement des images.  
- ImplÃ©mentation du mÃªme modÃ¨le dâ€™interpolant (SDE/ODE), adaptÃ© Ã  des entrÃ©es haute dimension.  
- EntraÃ®nement sur le **cluster de calcul CLEPS (INRIA)** pendant ~50 Ã©poques.  
- Ã‰chantillonnage de nouvelles images via intÃ©gration des Ã©quations diffÃ©rentielles associÃ©es.  
- Visualisation finale des images gÃ©nÃ©rÃ©es Ã  lâ€™Ã©poque 35 :

![RÃ©sultats sur le dataset Oxford Flowers (epoch 35)](interpolant_ODE_SDE/results/results_epoch_35_flowers.png)
![RÃ©sultats sur le dataset Oxford Flowers (epoch 60)](interpolant_ODE_SDE/results/results_epoch_60_flowers.png)
#### RÃ©sultats
- Les images gÃ©nÃ©rÃ©es sont **visuellement cohÃ©rentes** : formes florales, dÃ©gradÃ©s de couleurs, textures naturelles.  
- Les interpolants reproduisent fidÃ¨lement la diversitÃ© des donnÃ©es, confirmant leur **capacitÃ© de modÃ©lisation continue** entre bruit et structure.  
- La mÃ©thode SDE conserve une plus grande variabilitÃ©, tandis que lâ€™ODE tend vers une reconstruction plus stable mais moins expressive.

#### Apports du travail
- PremiÃ¨re mise en Å“uvre pratique du formalisme â€œStochastic Interpolantsâ€ au sein de lâ€™Ã©quipe ARGO.  
- RÃ©daction dâ€™un **notebook pÃ©dagogique destinÃ© aux Ã©lÃ¨ves de lâ€™Ã‰cole Polytechnique**, visant Ã  introduire les interpolants dans le cadre des modÃ¨les de diffusion.  
- Base de comparaison pour les expÃ©riences ultÃ©rieures dâ€™**assimilation de donnÃ©es** sur images et sur graphes.

---

> Ces deux notebooks forment le cÅ“ur thÃ©orique du stage : ils montrent comment un processus continu dâ€™interpolation probabiliste peut Ãªtre exploitÃ© pour la gÃ©nÃ©ration de donnÃ©es, et ouvrent la voie Ã  leur utilisation dans des contextes dâ€™assimilation.



## 4. Inpainting sur des arbres couvrants uniformes (UST)

Cette partie du projet sâ€™intÃ©resse Ã  lâ€™application des modÃ¨les de diffusion Ã  des **donnÃ©es structurÃ©es de type graphe**, sous forme dâ€™images de **labyrinthes reprÃ©sentant des arbres couvrants uniformes (Uniform Spanning Trees, UST)**.  
Lâ€™objectif est dâ€™examiner si un **modÃ¨le de diffusion conditionnelle** peut **â€œassimilerâ€ des propriÃ©tÃ©s physiques ou structurelles** telles que :
- **la connexitÃ©** (tous les nÅ“uds sont reliÃ©s),  
- **lâ€™absence de cycles**,  
- **le nombre dâ€™arÃªtes fixe** pour un graphe donnÃ©.

Le travail est regroupÃ© dans le dossier `mazes_inpainting_and_utils/`, qui contient les scripts suivants :

| Fichier | Description |
|----------|--------------|
| `inpainting_generating_chosen_mask.py` | Script principal dâ€™inpainting : permet de gÃ©nÃ©rer des masques arbitraires sur les UST et de complÃ©ter les zones manquantes via un modÃ¨le de diffusion. Lâ€™utilisateur peut **dessiner manuellement** le masque Ã  reconstituer. |
| `inpainting_mazes_training_generation_fixed_mask.py` | Variante expÃ©rimentale permettant dâ€™entraÃ®ner le modÃ¨le avec un masque fixe et de comparer les performances selon diffÃ©rents taux de masquage. |
| `utils_*.py` *(selon version)* | Fonctions auxiliaires pour la gÃ©nÃ©ration dâ€™UST (algorithme de Wilson), le traitement dâ€™images et la visualisation. |

---

### Principe

Lâ€™idÃ©e est de considÃ©rer les images dâ€™UST comme des â€œcartesâ€ partielles dâ€™un systÃ¨me Ã  complÃ©ter.  
Une portion du graphe est masquÃ©e, puis le modÃ¨le tente de **reconstruire la partie manquante** en respectant la cohÃ©rence globale.  

Lâ€™approche repose sur :
1. un **modÃ¨le de diffusion conditionnÃ©** sur les rÃ©gions visibles de lâ€™image ;  
2. une **technique de resampling** inspirÃ©e de *RePaint* (Lugmayr et al., 2022),  
   qui permet de rÃ©alimenter en variance les zones reconstruites afin dâ€™amÃ©liorer la continuitÃ© entre parties connues et complÃ©tÃ©es.

---

### Fonctionnement du script

- Le script charge un ensemble dâ€™UST gÃ©nÃ©rÃ©s par lâ€™algorithme de **Wilson**.  
- Lâ€™utilisateur dÃ©finit un **masque** (manuellement ou alÃ©atoirement) reprÃ©sentant les zones Ã  reconstruire.  
- Le modÃ¨le de diffusion rÃ©alise un processus de **bruitage / dÃ©bruitage** sur lâ€™image complÃ¨te, mais ne modifie que les zones masquÃ©es.  
- Le rÃ©sultat est sauvegardÃ© et affichÃ© pour comparaison avec lâ€™image initiale.

---

### Exemples de rÃ©sultats

#### Exemple 1 â€“ Masque manuel
Lâ€™utilisateur sÃ©lectionne un masque de forme libre.  
Le modÃ¨le tente ensuite de combler les zones manquantes.

![Inpainting avec masque manuel](UST_inpainting/results/result_mask_random.png)

#### Exemple 2 â€“ Masque complet
Lorsque le masque couvre toute lâ€™image, le modÃ¨le rÃ©alise une **gÃ©nÃ©ration complÃ¨te** Ã  partir du bruit initial.

![Inpainting sur masque complet](UST_inpainting/results/result_inpainting_full_mask.png)


---

### InterprÃ©tation des rÃ©sultats

Les reconstructions produites montrent une **bonne cohÃ©rence visuelle** avec les images originales :  
les motifs et textures locales sont correctement reproduits, les arÃªtes sâ€™alignent globalement avec la structure attendue.  

Cependant :
- certaines **zones contiennent des cycles** (non dÃ©sirÃ©s) ;  
- la **connexitÃ© nâ€™est pas toujours assurÃ©e**, avec parfois des arÃªtes isolÃ©es ;  
- les propriÃ©tÃ©s topologiques des UST ne sont donc **pas complÃ¨tement apprises** par le modÃ¨le de diffusion.

Ces limites montrent que si le modÃ¨le capture bien les **corrÃ©lations locales**, il nâ€™intÃ¨gre pas encore la **structure globale** imposÃ©e par la thÃ©orie des graphes.  
Une piste dâ€™amÃ©lioration, Ã©voquÃ©e dans le rapport, serait dâ€™intÃ©grer :
- des **contraintes structurelles explicites** (pÃ©nalisation de cycles, connexitÃ©) dans la loss,  
- ou une **diffusion directement sur le graphe** plutÃ´t que sur lâ€™image.

---

### Objectif de cette expÃ©rimentation

Ce travail dâ€™inpainting sert de **pont conceptuel** entre la diffusion sur images et lâ€™assimilation de donnÃ©es physiques :  
comme dans un systÃ¨me rÃ©el oÃ¹ certaines observations sont manquantes, le modÃ¨le doit â€œassimilerâ€ des informations partielles pour **reconstruire un Ã©tat complet cohÃ©rent**.

Il constitue donc une **premiÃ¨re tentative dâ€™assimilation par modÃ¨le de diffusion**, avant les expÃ©riences suivantes sur graphes.

---

> Ces expÃ©riences montrent que les modÃ¨les de diffusion peuvent restituer efficacement la structure apparente dâ€™un systÃ¨me, mais que la prÃ©servation des lois internes (ici les propriÃ©tÃ©s dâ€™un UST) nÃ©cessite des contraintes explicites.  
> Ce constat motivera la derniÃ¨re partie du projet : **la diffusion directement sur graphes**, afin de capturer les relations topologiques sans passer par lâ€™image.


## 5. Diffusion sur graphes â€” GÃ©nÃ©ration dâ€™UST

Ã€ la suite des limites observÃ©es avec la mÃ©thode dâ€™**inpainting par diffusion sur images**, une nouvelle approche a Ã©tÃ© testÃ©e :  
appliquer la **diffusion directement sur les graphes** eux-mÃªmes, plutÃ´t que sur leurs reprÃ©sentations visuelles.  

Lâ€™objectif est de voir si un **modÃ¨le de diffusion discrÃ¨te** peut apprendre Ã  gÃ©nÃ©rer des **arbres couvrants uniformes (UST)** â€” câ€™est-Ã -dire des graphes connexes, acycliques et couvrant tous les nÅ“uds â€” Ã  partir dâ€™une matrice dâ€™adjacence bruitÃ©e.

---

### Structure du dossier `UST_diffusion/`

| Fichier / notebook | RÃ´le |
|---------------------|------|
| `sample_ppgn.ipynb` | Notebook principal : visualisation et Ã©chantillonnage des graphes gÃ©nÃ©rÃ©s par diffusion. |
| `train_ppgn_simple_adj_neigh.py` | Script dâ€™entraÃ®nement du modÃ¨le de diffusion sur matrices dâ€™adjacence. ImplÃ©mente la logique de bruitage / dÃ©bruitage et la loss. |
| `model_ppgn.py` | DÃ©finition du rÃ©seau de neurones principal (**PPGN** â€” Powerful Graph Network), architecture inspirÃ©e des *Graph Neural Networks* (message passing). |
| `graphs.py` | Fonctions utilitaires : gÃ©nÃ©ration de graphes de rÃ©fÃ©rence via lâ€™algorithme de **Wilson**, crÃ©ation de matrices dâ€™adjacence, visualisation et mesure de propriÃ©tÃ©s (connexitÃ©, cycles, etc.). |
| `data/` *(optionnel)* | Contient les datasets de graphes utilisÃ©s pour lâ€™entraÃ®nement et la validation. |

---

### MÃ©thodologie

#### 1. ReprÃ©sentation des donnÃ©es
Chaque graphe est reprÃ©sentÃ© par sa **matrice dâ€™adjacence** \( A \in \{0,1\}^{n \times n} \).  
Les graphes dâ€™entraÃ®nement sont des **UST gÃ©nÃ©rÃ©s par lâ€™algorithme de Wilson**.  

#### 2. Processus de diffusion
Un **bruit discret** est ajoutÃ© sur les arÃªtes :
- Ã  chaque Ã©tape, certaines arÃªtes sont ajoutÃ©es ou supprimÃ©es avec une probabilitÃ© donnÃ©e ;
- le modÃ¨le apprend Ã  prÃ©dire le bruit ajoutÃ© entre \( A_t \) (bruitÃ©) et \( A_{t-1} \) (Ã©tat prÃ©cÃ©dent).

#### 3. RÃ©seau utilisÃ©
Le modÃ¨le est basÃ© sur une architecture **PPGN (Powerful Graph Network)**, adaptÃ©e Ã  la manipulation de matrices dâ€™adjacence :  
- elle encode les relations entre nÅ“uds via un mÃ©canisme de message passing ;  
- elle prÃ©serve la permutation-invariance ;  
- elle permet dâ€™apprendre des reprÃ©sentations locales et globales du graphe.

#### 4. Fonction de perte
La loss intÃ¨gre plusieurs termes :
- **erreur de reconstruction** (prÃ©diction du bruit) ;
- **pÃ©nalitÃ©s structurelles** :
  - nombre de cycles,
  - connexitÃ© du graphe,
  - nombre total dâ€™arÃªtes (fixÃ© Ã  \( n-1 \) pour un UST),
  - nÅ“uds isolÃ©s.  

Chaque pÃ©nalisation est pondÃ©rÃ©e par un hyperparamÃ¨tre, ajustÃ© expÃ©rimentalement.

---

### ExpÃ©riences

Les graphes ont Ã©tÃ© gÃ©nÃ©rÃ©s et entraÃ®nÃ©s pour diffÃ©rentes tailles de grilles (de \(4\times4\) Ã  \(10\times10\)).  
Les figures ci-dessous illustrent le **dÃ©bruitage progressif** dâ€™un graphe vers une structure proche dâ€™un UST.

| Ã‰tape | Description | Observation |
|-------|--------------|-------------|
| 1 | Graphe bruitÃ© (arÃªtes alÃ©atoires) | Nombreux cycles et composantes isolÃ©es |
| 2 | Diffusion discrÃ¨te sur 64 Ã©tapes | Suppression progressive des cycles |
| 3 | Graphe reconstruit | Structure proche dâ€™un arbre couvrant |

Ã€ la fin du processus, les graphes produits prÃ©sentent souvent **moins de cycles** et une **meilleure connexitÃ©** que les graphes alÃ©atoires de dÃ©part.

---

### Ã‰valuation quantitative

Pour quantifier la qualitÃ© des graphes gÃ©nÃ©rÃ©s :
- On applique un **post-traitement** supprimant les cycles restants et connectant les composantes isolÃ©es.
- On compte le **nombre moyen de modifications nÃ©cessaires** pour transformer le graphe gÃ©nÃ©rÃ© en un vÃ©ritable UST.

| Taille du graphe | Changements moyens (graphes alÃ©atoires) | Changements moyens (graphes gÃ©nÃ©rÃ©s par diffusion) |
|------------------:|----------------------------------------:|----------------------------------------------------:|
| 16 nÅ“uds | 7.3 | **2.5** |
| 36 nÅ“uds | 13.8 | **7.1** |
| 64 nÅ“uds | 21.4 | **11.3** |

Les graphes issus du modÃ¨le nÃ©cessitent environ **deux fois moins de corrections** que des graphes purement alÃ©atoires, ce qui montre que la diffusion apprend partiellement les propriÃ©tÃ©s structurelles recherchÃ©es.

---

### InterprÃ©tation et perspectives

- Le modÃ¨le de diffusion **assimile partiellement les lois structurelles** des arbres couvrants : les graphes gÃ©nÃ©rÃ©s sont souvent proches dâ€™UST, surtout pour de petites tailles.  
- Pour les graphes plus grands, les performances se dÃ©gradent Ã  cause :
  - de la **sparsitÃ©** croissante des matrices dâ€™adjacence,  
  - dâ€™un **manque de capacitÃ©** du modÃ¨le,  
  - et de la **difficultÃ© de rÃ©gularisation** des contraintes topologiques.

Des pistes dâ€™amÃ©lioration proposÃ©es :
- reprÃ©senter les graphes sous forme de **vecteurs dâ€™arÃªtes autorisÃ©es** plutÃ´t que matrices carrÃ©es ;
- introduire une **pÃ©nalisation adaptative** (cycles / connexitÃ©) au cours de la gÃ©nÃ©ration ;
- combiner diffusion discrÃ¨te et apprentissage par renforcement pour contraindre la topologie en ligne.

---

### Bilan de cette derniÃ¨re Ã©tape

Cette expÃ©rimentation conclut le stage en montrant la **faisabilitÃ© dâ€™une diffusion sur graphes** :  
mÃªme si les modÃ¨les ne captent pas encore toutes les propriÃ©tÃ©s physiques, ils constituent une premiÃ¨re base pour une **assimilation de donnÃ©es topologique**.  

> En somme, la transition de lâ€™inpainting dâ€™images vers la diffusion sur graphes reprÃ©sente un changement dâ€™Ã©chelle conceptuel :  
> passer dâ€™une assimilation â€œvisuelleâ€ Ã  une assimilation â€œstructurelleâ€, plus proche des systÃ¨mes physiques modÃ©lisÃ©s par graphes.


